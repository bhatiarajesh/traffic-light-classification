{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Reference: https://github.com/udacity/CarND-Object-Detection-Lab\n",
    "class TLClassifier(object):\n",
    "    def __init__(self):\n",
    "        start = time.time()\n",
    "        graph_filename = '../site_graph.pb'\n",
    "        print(\"Initializing TensorFlow...\")\n",
    "        self.detection_graph = tf.Graph()\n",
    "        # configure for a GPU\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        # load trained tensorflow graph\n",
    "        with self.detection_graph.as_default():\n",
    "            graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(graph_filename, 'rb') as f:\n",
    "                graph_def.ParseFromString(f.read())\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "            self.sess = tf.Session(graph=self.detection_graph, config=config)\n",
    "            # configure input and output\n",
    "            self.image_tensor   = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            self.dboxes         = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            self.dscores        = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            self.dclasses       = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "            startA = time.time()\n",
    "            # initialize the network by running a randomized image\n",
    "            image = np.asarray(np.random.rand(300,300,3), dtype=\"uint8\")\n",
    "            image_expanded = np.expand_dims(image, axis=0)\n",
    "            _ = self.sess.run([self.dboxes, self.dscores, self.dclasses, self.num_detections],\n",
    "              feed_dict={self.image_tensor: image_expanded})\n",
    "        endA = time.time()\n",
    "        print('First time run duration: ', endA-startA)\n",
    "        end = time.time()\n",
    "        print('Total initialization time: ', end-start)\n",
    "\n",
    "    # Convert normalized box coordinates to pixels\n",
    "    def to_image_coords(self, box, dim):\n",
    "        \"\"\"\n",
    "        The original box coordinate output is normalized, i.e [0, 1].\n",
    "\n",
    "        This converts it back to the original coordinate based on the image\n",
    "        size. Optimized.\n",
    "        \"\"\"\n",
    "        height, width = dim[0], dim[1]\n",
    "        box_pixel = [int(box[0] * height), int(box[1] * width), int(box[2] * height), int(box[3] * width)]\n",
    "        return np.array(box_pixel)\n",
    "\n",
    "    def locateTL(self, image):\n",
    "        box = [0, 0, 0, 0]\n",
    "        with self.detection_graph.as_default():\n",
    "            image_expanded = np.expand_dims(image, axis=0)\n",
    "            (boxes, scores, classes, num_detections) = self.sess.run(\n",
    "              [self.dboxes, self.dscores, self.dclasses, self.num_detections],\n",
    "              feed_dict={self.image_tensor: image_expanded})\n",
    "            \n",
    "            # Remove unnecessary dimensions\n",
    "            boxes   = np.squeeze(boxes)\n",
    "            class_  = np.int32(np.squeeze(classes).tolist())\n",
    "            scores  = np.squeeze(scores)\n",
    "            index = next((i for i, clsid in enumerate(class_) if clsid < 4), None)\n",
    "            if index == None:\n",
    "                print('No traffic light detected')\n",
    "            elif scores[index] <= 0.4:\n",
    "                print('Confidence: ', scores[index])\n",
    "            else:\n",
    "                b = self.to_image_coords(boxes[index], image.shape[0:2])\n",
    "                b_w = b[3]-b[1]\n",
    "                ratio = (b[2]-b[0]) / (b_w + 0.00001)\n",
    "                if (b_w >= 20) and (ratio > 2.0):\n",
    "                    print('Confidence: ', scores[index])\n",
    "                    box = b\n",
    "                else:\n",
    "                    print(b_h, b_w, ratio)\n",
    "                    print('Found, but bad ratio or too narrow')\n",
    "        return box\n",
    "\n",
    "    # Classify a traffic light based on simple geometric properties\n",
    "    # Expects a gray-scale image\n",
    "    def classifyTL(self, image_data):\n",
    "        print('____________________________________________________________________')\n",
    "        # get the image center geometry\n",
    "        midX = int(image_data.shape[1]/2)\n",
    "        midY = int(image_data.shape[0]/2)\n",
    "        thirdY = int(image_data.shape[0]/3)\n",
    "        p = int(thirdY/4) #patch size\n",
    "        # get the center point of each ROI\n",
    "        rROI = ( int(thirdY/2) , midX )\n",
    "        yROI = ( midY, midX )\n",
    "        gROI = ( midY+thirdY , midX )\n",
    "        # find the average from each center patch\n",
    "        rROI = int(np.mean(image_data[rROI[0]-p:rROI[0]+p, rROI[1]-p:rROI[1]+p]))\n",
    "        yROI = int(np.mean(image_data[yROI[0]-p:yROI[0]+p, yROI[1]-p:yROI[1]+p]))\n",
    "        gROI = int(np.mean(image_data[gROI[0]-p:gROI[0]+p, gROI[1]-p:gROI[1]+p]))\n",
    "        # perform simple brightness comparisons and print for humans\n",
    "        if (gROI > yROI) and (gROI > rROI):\n",
    "            print(\">>> GREEN <<<\")\n",
    "        elif (yROI > gROI) and (yROI > rROI):\n",
    "            print(\">>> YELLOW <<<\")\n",
    "        elif (rROI > yROI) and (rROI > gROI):\n",
    "            print(\">>> RED <<<\")\n",
    "        if (gROI > yROI) and (gROI > rROI):\n",
    "            return 1 # GO\n",
    "        else:\n",
    "            return 0 # STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TensorFlow...\n",
      "First time run duration:  4.571080207824707\n",
      "Total initialization time:  7.856497764587402\n"
     ]
    }
   ],
   "source": [
    "tc = TLClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence:  0.995318\n",
      "[ 35  88 122 116]\n",
      "Detection time:  0.024503231048583984\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"../image/l5e-300y.png\")\n",
    "image_data = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#image_data = (image_data - 128.)/128.\n",
    "#image_data = adjust_gamma(image_data, 0.64)\n",
    "#image_data = np.dstack((image_data,image_data,image_data))\n",
    "start = time.time()\n",
    "b = tc.locateTL(image_data)\n",
    "end = time.time()\n",
    "print(b)\n",
    "print('Detection time: ', end-start)\n",
    "\n",
    "#{1: {'id': 1, 'name': 'Green'}, \n",
    "# 2: {'id': 2, 'name': 'Red'}, \n",
    "# 3: {'id': 3, 'name': 'Yellow'}, \n",
    "# 4: {'id': 4, 'name': 'off'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      ">>> YELLOW <<<\n",
      "STOP\n",
      "Classification time:  0.0010001659393310547\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# If there is no detection or low-confidence detection\n",
    "if np.array_equal(b, np.zeros(4)):\n",
    "    print ('unknown')\n",
    "else:\n",
    "    img_tl = img[b[0]:b[2], b[1]:b[3]]\n",
    "    img_tl = cv2.cvtColor(img_tl, cv2.COLOR_BGR2HSV)[:,:,2]\n",
    "    signal_status = tc.classifyTL(img_tl)\n",
    "    print(\"GO\" if signal_status else \"STOP\")\n",
    "end = time.time()\n",
    "print('Classification time: ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence:  0.728387\n",
      "[ 59 221 127 243]\n",
      "Detection time:  0.03550457954406738\n",
      "____________________________________________________________________\n",
      ">>> RED <<<\n",
      "STOP\n",
      "Classification time:  0.0004999637603759766\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "img = cv2.imread(\"../image/vred-300.png\")\n",
    "image_data = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "b = tc.locateTL(image_data)\n",
    "print(b)\n",
    "end = time.time()\n",
    "print('Detection time: ', end-start)\n",
    "start = time.time()\n",
    "# If there is no detection or low-confidence detection\n",
    "if np.array_equal(b, np.zeros(4)):\n",
    "    print ('unknown')\n",
    "else:\n",
    "    img_tl = img[b[0]:b[2], b[1]:b[3]]\n",
    "    img_tl = cv2.cvtColor(img_tl, cv2.COLOR_BGR2HSV)[:,:,2]\n",
    "    signal_status = tc.classifyTL(img_tl)\n",
    "    print(\"GO\" if signal_status else \"STOP\")\n",
    "end = time.time()\n",
    "print('Classification time: ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[162  27  76]\n",
      "  [  7 210 202]\n",
      "  [182 240 254]\n",
      "  ..., \n",
      "  [ 20 212 196]\n",
      "  [118  36 176]\n",
      "  [167  21 205]]\n",
      "\n",
      " [[ 72 137  97]\n",
      "  [142  64 144]\n",
      "  [142 145 210]\n",
      "  ..., \n",
      "  [218  12 233]\n",
      "  [237  28   7]\n",
      "  [  7 205  73]]\n",
      "\n",
      " [[191 203  97]\n",
      "  [224  52 192]\n",
      "  [  8 193  98]\n",
      "  ..., \n",
      "  [ 74 112  91]\n",
      "  [ 45 118  10]\n",
      "  [130  42 191]]\n",
      "\n",
      " ..., \n",
      " [[ 17  96 210]\n",
      "  [200  27   1]\n",
      "  [  9 239 128]\n",
      "  ..., \n",
      "  [239   9 241]\n",
      "  [230 245 129]\n",
      "  [ 73 137 198]]\n",
      "\n",
      " [[164 251  83]\n",
      "  [ 86 212 207]\n",
      "  [156 145 221]\n",
      "  ..., \n",
      "  [252 220 207]\n",
      "  [136 232  50]\n",
      "  [239  75 243]]\n",
      "\n",
      " [[253 196 154]\n",
      "  [ 39 253 248]\n",
      "  [102 125  93]\n",
      "  ..., \n",
      "  [ 96 104  70]\n",
      "  [  1 113 133]\n",
      "  [ 37  68  50]]]\n"
     ]
    }
   ],
   "source": [
    "#image = np.asarray(np.random.rand(300,300,3)*2.-1.)\n",
    "image = np.asarray(np.random.rand(300,300,3)*255, dtype=\"uint8\")\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
